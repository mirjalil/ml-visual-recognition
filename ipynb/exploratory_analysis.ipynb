{
 "metadata": {
  "name": "",
  "signature": "sha256:de863a2902a8afda29bc06f9d9729bc8f823b9d151464f0010b76026c02d2ed1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas\n",
      "import scipy, scipy.spatial\n",
      "import sklearn\n",
      "import sys\n",
      "\n",
      "from matplotlib import pyplot as plt\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = pandas.read_table(\"~/Downloads/data/ml/label_train.txt\", sep=\" \", dtype='int', header=None)\n",
      "\n",
      "y.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>161</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>163</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>56</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>119</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>138</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "     0\n",
        "0  161\n",
        "1  163\n",
        "2   56\n",
        "3  119\n",
        "4  138"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.unique(y[0], return_counts=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
        "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
        "         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
        "         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
        "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
        "        105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
        "        118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
        "        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
        "        144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
        "        157, 158, 159, 160, 161, 162, 163, 164]),\n",
        " array([  1263,   1261,   1255,   1256,   1252,   1235,   1240,   1264,\n",
        "          1256,   1281,   1245,   1278,   1278,   1253,   1255,   1255,\n",
        "          1291,   1277,   1308,   1285,   1322,   1309,   1318,   1322,\n",
        "          1327,   1339,   1361,   1361,   1335,   1396,   1359,   1393,\n",
        "          1373,   1356,   1398,   1416,   1386,   1398,   1396,   1404,\n",
        "          1430,   1398,   1416,   1406,   1420,   1445,   1433,   1445,\n",
        "          1454,   1451,   1481,   1482,   1477,   1474,   1478,   1486,\n",
        "          1512,   1492,   1557,   1557,   1548,   1530,   1574,   1582,\n",
        "          1606,   1611,   1666,   1650,   1704,   1739,   1735,   1743,\n",
        "          1728,   1796,   1737,   1810,   1822,   1864,   1847,   1838,\n",
        "          1857,   1913,   1910,   1917,   2006,   1992,   2033,   2063,\n",
        "          2072,   2063,   2096,   2128,   2134,   2206,   2215,   2212,\n",
        "          2258,   2279,   2287,   2319,   2356,   2435,   2438,   2491,\n",
        "          2486,   2485,   2502,   2555,   2594,   2629,   2575,   2587,\n",
        "          2777,   2875,   2897,   2884,   2978,   3087,   3179,   3368,\n",
        "          3388,   3421,   3409,   3453,   3536,   3586,   3615,   3696,\n",
        "          3821,   3802,   3934,   4059,   4069,   4253,   4819,   4939,\n",
        "          5038,   5259,   5310,   6080,   6487,   6623,   7256,   8279,\n",
        "          9069,   9221,   9707,   9998,  10557,  10645,  11484,  12382,\n",
        "         12858,  16548,  18562,  21943,  30679,  34092,  45439,  60513,\n",
        "         64478,  65211,  92241, 130122]))"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "522775"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv_idx = np.random.choice(y.shape[0], 100000, replace=False)\n",
      "\n",
      "with open('/home/vahid/Downloads/data/ml/data_train.txt', 'r') as fp:\n",
      "    with open('../data/data_cv.txt', 'w') as f1, open('../data/label_cv.txt', 'w') as y1, \\\n",
      "        open('../data/data_tr.txt', 'w') as f2, open('../data/label_tr.txt', 'w') as y2:\n",
      "        n = 0\n",
      "        for line in fp:\n",
      "            if np.any(n == cv_idx):\n",
      "                f1.write('%s'%line)\n",
      "                y1.write('%d\\n'%y[0][n])\n",
      "            else:\n",
      "                f2.write('%s'%line)\n",
      "                y2.write('%d\\n'%y[0][])\n",
      "            n += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xc\n",
      "pickle.dump( r, open( \"../data/sum_features.dat\", \"wb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Cal Mean and Var. of each feature for each class\n",
      "\n",
      "ndim = 900\n",
      "def calClassStat(data_fname, y):\n",
      "    \"\"\" Return a dictionary: class_label:(mean_vec, var_vec, num)\n",
      "        data_fname is the file containing all the features and samples\n",
      "        y: class labels for each sample\n",
      "    \"\"\"\n",
      "    clstat={}\n",
      "    yuniq = np.unique(y)\n",
      "    for ci in yuniq:\n",
      "        clstat[ci] = [np.zeros(shape=ndim), np.zeros(shape=ndim), 0]\n",
      "        clstat['all'] = [np.zeros(shape=ndim), np.zeros(shape=ndim), 0]\n",
      "    \n",
      "    with open(data_fname, 'r') as fp:\n",
      "        n = 0\n",
      "        for line in fp:\n",
      "            line = line.strip().split()\n",
      "            vals = np.empty(shape=ndim, dtype=int)\n",
      "            for i,v in enumerate(line):\n",
      "                vals[i] = int(v)            \n",
      "            label = y[n]\n",
      "            assert(len(line) == ndim)\n",
      "            clstat[label][0] += vals\n",
      "            clstat[label][1] += vals**2\n",
      "            clstat[label][2] += 1\n",
      "            n += 1\n",
      "            \n",
      "    \n",
      "    for ci in yuniq:\n",
      "        clstat['all'][0] += clstat[ci][0]\n",
      "        clstat['all'][1] += clstat[ci][1]\n",
      "        clstat['all'][2] += clstat[ci][2]\n",
      "    \n",
      "            \n",
      "    return (clstat)\n",
      "\n",
      "r = calClassStat('/home/vahid/Downloads/data/ml/data_train.txt', y[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "pickle.dump( r, open( \"../data/sum_features.dat\", \"wb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Calclulate Standardized Mean Difference Between Classes\n",
      "\n",
      "def calStandMeanDiff(y, yneg, ypos):\n",
      "    sx  = np.zeros(shape=ndim, dtype=float)\n",
      "    ssx = np.zeros(shape=ndim, dtype=float)\n",
      "\n",
      "    \n",
      "    n1 = np.sum(np.in1d(y, yneg))\n",
      "    n2 = np.sum(np.in1d(y, ypos))\n",
      "    sys.stderr.write(\"Number of samples in NegClass: %d and PosClass: %d \\n\"%(n1, n2))\n",
      "    \n",
      "    for yi in yneg:\n",
      "        sx += r[yi][0]\n",
      "        ssx += r[yi][1]\n",
      "    r1_mean = sx / float(n1)\n",
      "    r1_var = (ssx - 2*sx*r1_mean + r1_mean**2) / float(n1)\n",
      "\n",
      "    sx  = np.zeros(shape=ndim, dtype=float)\n",
      "    ssx = np.zeros(shape=ndim, dtype=float)\n",
      "    for yi in ypos:\n",
      "        sx += r[yi][0]\n",
      "        ssx += r[yi][1]\n",
      "    r2_mean = sx / float(n2)\n",
      "    r2_var = (ssx - 2*sx*r2_mean + r2_mean**2) / float(n2)\n",
      "\n",
      "    tot_mean = r['all'][0] / float(r['all'][2])\n",
      "    tot_var  = (r['all'][1] - 2*r['all'][0]*tot_mean + tot_mean**2) / float(r['all'][2])\n",
      "\n",
      "    rdiff = (r1_mean - r2_mean) / np.sqrt(tot_var)\n",
      "\n",
      "    return (rdiff)\n",
      "\n",
      "\n",
      "## unit test:\n",
      "mean_test = calStandMeanDiff(y, np.arange(1,157), np.arange(157, 165)) \n",
      "print(np.sum(mean_test > 0.1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "332\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Number of samples in NegClass: 477225 and PosClass: 522775 \n"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Classify items belonging to first half (1) Second half (-1)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Finding Good Features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rdiff = calStandMeanDiff(y, np.arange(1,157), np.arange(157, 165)) \n",
      "\n",
      "\n",
      "## Good Features:\n",
      "goodfeatures = np.where(rdiff > 0.1)[0]\n",
      "\n",
      "goodfeatures"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Number of samples in NegClass: 477225 and PosClass: 522775 \n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 107,
       "text": [
        "array([  1,   2,   5,   6,  14,  15,  24,  25,  35,  38,  39,  40,  42,\n",
        "        43,  48,  52,  56,  58,  59,  61,  65,  69,  71,  74,  79,  80,\n",
        "        81,  91,  92,  94,  97,  99, 110, 111, 112, 116, 118, 119, 122,\n",
        "       127, 129, 133, 137, 138, 139, 140, 143, 145, 146, 148, 149, 151,\n",
        "       152, 153, 158, 159, 161, 163, 166, 167, 168, 169, 175, 178, 180,\n",
        "       184, 185, 186, 187, 188, 193, 195, 196, 198, 199, 204, 206, 208,\n",
        "       210, 214, 215, 216, 217, 219, 221, 222, 223, 224, 225, 229, 234,\n",
        "       237, 240, 247, 254, 255, 256, 257, 258, 261, 263, 265, 267, 272,\n",
        "       273, 274, 277, 278, 280, 281, 282, 286, 288, 289, 294, 295, 300,\n",
        "       307, 308, 315, 316, 318, 320, 322, 328, 329, 330, 332, 334, 336,\n",
        "       338, 340, 341, 343, 344, 348, 350, 352, 353, 355, 359, 367, 372,\n",
        "       374, 381, 387, 388, 389, 397, 398, 399, 400, 402, 404, 406, 407,\n",
        "       408, 412, 413, 414, 416, 417, 421, 422, 425, 428, 432, 439, 440,\n",
        "       443, 445, 447, 451, 457, 461, 462, 464, 466, 467, 473, 485, 489,\n",
        "       490, 492, 498, 500, 501, 504, 507, 508, 510, 511, 517, 524, 526,\n",
        "       527, 530, 531, 537, 539, 541, 542, 544, 547, 556, 561, 563, 564,\n",
        "       566, 570, 571, 573, 576, 578, 579, 581, 582, 584, 585, 588, 589,\n",
        "       594, 601, 602, 603, 605, 608, 609, 613, 617, 624, 628, 632, 633,\n",
        "       634, 641, 643, 645, 646, 652, 653, 657, 658, 661, 665, 666, 667,\n",
        "       673, 676, 680, 681, 686, 692, 698, 703, 705, 711, 712, 714, 716,\n",
        "       717, 718, 720, 722, 725, 726, 727, 730, 732, 735, 738, 742, 746,\n",
        "       747, 748, 751, 753, 757, 758, 759, 760, 762, 764, 766, 770, 772,\n",
        "       773, 774, 776, 778, 779, 784, 785, 786, 790, 796, 798, 805, 806,\n",
        "       811, 812, 815, 816, 817, 818, 821, 822, 825, 828, 829, 833, 841,\n",
        "       849, 853, 854, 855, 861, 863, 864, 869, 871, 874, 876, 877, 878,\n",
        "       879, 881, 884, 886, 890, 892, 894])"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Read a Random Sample"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def readRandomSample(data_fname, y, size, goodfeat=None, acc_miny=None, acc_maxy=None):\n",
      "    \"\"\" Read a random sample\n",
      "    \"\"\"\n",
      "    if goodfeat is None:\n",
      "        goodfeat = np.arange(ndim)\n",
      "    Xsub = np.empty(shape=(size,goodfeat.shape[0]), dtype=float)\n",
      "    ysub = np.zeros(shape=size, dtype=int)\n",
      "\n",
      "    if acc_miny is None:\n",
      "        acc_miny = np.min(y)\n",
      "    if acc_maxy is None:\n",
      "        acc_maxy = np.max(y)\n",
      "        \n",
      "    #yuniq, ycount = np.unique(y, return_counts=True)\n",
      "    #tot_acceptable = np.sum(ycount[np.where((yuniq >= acc_miny) & (yuniq <= acc_maxy))[0]])\n",
      "    \n",
      "    acceptable_indx = np.where((y>=acc_miny) & (y<=acc_maxy))[0]\n",
      "    assert(acceptable_indx.shape[0] > size)\n",
      "    choice_indx = np.sort(np.random.choice(acceptable_indx, size, replace=False))\n",
      "    #print(choice_indx.shape)\n",
      "    #sys.stderr.write(\"Total Accetables: --> %d\"%(tot_acceptable))\n",
      "    \n",
      "    #proba = 1.0 - size/float(tot_acceptable)\n",
      "    \n",
      "        \n",
      "    with open(data_fname, 'r') as fp:\n",
      "        n = 0\n",
      "        nf = 0\n",
      "        for line in fp:\n",
      "#            if (y[n] >= acc_miny and y[n]<=acc_maxy):\n",
      "#                if np.random.uniform(low=0, high=1) > proba and nf < size:\n",
      "            if nf < size:\n",
      "                if n == choice_indx[nf]:\n",
      "                    line = line.strip().split()\n",
      "                    ix = -1\n",
      "                    for i,v in enumerate(line):\n",
      "                        if np.any(goodfeat == i):\n",
      "                            ix += 1\n",
      "                            Xsub[nf,ix] = int(v)\n",
      "                    ysub[nf] = y[n]\n",
      "\n",
      "                    nf += 1\n",
      "            n += 1\n",
      "    return(Xsub, ysub)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## unit testing readRandomSample()\n",
      "gf_test = np.arange(21,35)\n",
      "Xsub, ysub = readRandomSample('/home/vahid/Downloads/data/ml/data_train.txt', y[0], \\\n",
      "                              size=2000, goodfeat=gf_test, acc_miny=15, acc_maxy=20)\n",
      "\n",
      "print(Xsub.shape)\n",
      "print(np.unique(ysub))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(2000,)\n",
        "(2000, 14)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[15 16 17 18 19 20]\n"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Performance Evaluation\n",
      "def evalPerformance(ytrue, ypred):\n",
      "    tp = np.sum(ypred[np.where(ytrue ==  1)[0]] == 1)\n",
      "    fp = np.sum(ypred[np.where(ytrue == -1)[0]] == 1)\n",
      "    tn = np.sum(ypred[np.where(ytrue == -1)[0]] == -1)\n",
      "    fn = ytrue.shape[0]-(tp+fp+tn)\n",
      "    sys.stderr.write('%d %d %d %d\\n'%(tp,fp,tn,fn))\n",
      "    prec = tp / float(tp + fp)\n",
      "    recall  = tp / float(tp + fn)\n",
      "    f1score = 2*tp/float(2*tp + fp + fn)\n",
      "\n",
      "    return (prec, recall, f1score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xsub, ysub = readRandomSample('/home/vahid/Downloads/data/ml/data_train.txt', y[0], size=20000, goodfeat=goodfeatures)\n",
      "\n",
      "ysub[np.where(ysub <= 156)[0]] = -1\n",
      "ysub[np.where(ysub  > 156)[0]] =  1\n",
      "\n",
      "#Xsub = Xsub[:, goodfeatures]\n",
      "Xsub = (Xsub - np.mean(Xsub, axis=0)) / np.std(Xsub, axis=0)\n",
      "\n",
      "Xsub.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 159,
       "text": [
        "(20000, 332)"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.svm\n",
      "\n",
      "ntot = Xsub.shape[0]\n",
      "tr_idx = np.random.choice(ntot, size=ntot/2, replace=False)\n",
      "ts_idx = np.setdiff1d(np.arange(ntot), tr_idx, assume_unique=True)\n",
      "yts = ysub[ts_idx]\n",
      "\n",
      "for c in [0.0001, 0.001, 0.01, 0.1, 1.0]:\n",
      "    for gm in [0.001, 0.01, 0.1, 1.0]:\n",
      "        clf = sklearn.svm.SVC(C=c, kernel='rbf', gamma=gm)\n",
      "        clf.fit(Xsub[tr_idx, :], ysub[tr_idx])\n",
      "        ypred = clf.predict(Xsub[ts_idx, :])\n",
      "        prec, recall, f1score = evalPerformance(yts, ypred)\n",
      "        print (\"C=%.4f Gamma=%.4f  ==> Prec:%.3f  Recall:%.3f  F1Score:%.3f\"%(c, gm, prec, recall, f1score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "5270 4730 0 0\n",
        "5270 4730 0 0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C=0.0001 Gamma=0.0010  ==> Prec:0.527  Recall:1.000  F1Score:0.690\n",
        "C=0.0001 Gamma=0.0100  ==> Prec:0.527  Recall:1.000  F1Score:0.690"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0001 Gamma=0.1000  ==> Prec:0.527  Recall:1.000  F1Score:0.690"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "5270 4730 0 0\n",
        "5270 4730 0 0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0001 Gamma=1.0000  ==> Prec:0.527  Recall:1.000  F1Score:0.690"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0010 Gamma=0.0010  ==> Prec:0.527  Recall:1.000  F1Score:0.690"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "5270 4730 0 0\n",
        "5270 4730 0 0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0010 Gamma=0.0100  ==> Prec:0.527  Recall:1.000  F1Score:0.690"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0010 Gamma=0.1000  ==> Prec:0.527  Recall:1.000  F1Score:0.690"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "5270 4730 0 0\n",
        "5270 4730 0 0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0010 Gamma=1.0000  ==> Prec:0.527  Recall:1.000  F1Score:0.690"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0100 Gamma=0.0010  ==> Prec:0.662  Recall:0.827  F1Score:0.735"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "4360 2229 2501 910\n",
        "2836 855 3875 2434\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0100 Gamma=0.0100  ==> Prec:0.768  Recall:0.538  F1Score:0.633"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0100 Gamma=0.1000  ==> Prec:0.527  Recall:1.000  F1Score:0.690"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "5270 4730 0 0\n",
        "5270 4730 0 0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0100 Gamma=1.0000  ==> Prec:0.527  Recall:1.000  F1Score:0.690"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=0.0010  ==> Prec:0.699  Recall:0.789  F1Score:0.742"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "4160 1790 2940 1110\n",
        "3351 1120 3610 1919\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=0.0100  ==> Prec:0.749  Recall:0.636  F1Score:0.688"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=0.1000  ==> Prec:0.834  Recall:0.152  F1Score:0.257"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "800 159 4571 4470\n",
        "5270 4730 0 0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=1.0000  ==> Prec:0.527  Recall:1.000  F1Score:0.690"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=1.0000 Gamma=0.0010  ==> Prec:0.710  Recall:0.786  F1Score:0.746"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "4140 1688 3042 1130\n",
        "3666 1244 3486 1604\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=1.0000 Gamma=0.0100  ==> Prec:0.747  Recall:0.696  F1Score:0.720"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=1.0000 Gamma=0.1000  ==> Prec:0.825  Recall:0.261  F1Score:0.397"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "1378 293 4437 3892\n",
        "5268 4730 0 2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=1.0000 Gamma=1.0000  ==> Prec:0.527  Recall:1.000  F1Score:0.690"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Learning Curve"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Picking the best C and gamma (C=1, gamma=0.1)\n",
      "\n",
      "for n in [1000, 2000, 4000, 8000, 16000, 32000]:\n",
      "    Xsub, ysub = readRandomSample('/home/vahid/Downloads/data/ml/data_train.txt', y[0], size=n, goodfeat=goodfeatures)\n",
      "\n",
      "    ysub[np.where(ysub <= 156)[0]] = -1\n",
      "    ysub[np.where(ysub  > 156)[0]] =  1\n",
      "\n",
      "    #Xsub = Xsub[:, goodfeatures]\n",
      "    #Xsub = (Xsub - np.mean(Xsub, axis=0)) / np.std(Xsub, axis=0)\n",
      "    \n",
      "    sys.stderr.write('\\nSize = %d  ==> '%(n))\n",
      "    Tp = [0,0,0,0,0]\n",
      "    Fp = [0,0,0,0,0]\n",
      "    Tn = [0,0,0,0,0]\n",
      "    Fn = [0,0,0,0,0]\n",
      "    for i in range(5):\n",
      "        tr_idx = np.random.choice(n, size=n/2, replace=False)\n",
      "        ts_idx = np.setdiff1d(np.arange(n), tr_idx, assume_unique=True)\n",
      "        yts = ysub[ts_idx]\n",
      "\n",
      "        clf = sklearn.svm.SVC(C=1.0, kernel='rbf', gamma=0.10)\n",
      "        clf.fit(Xsub[tr_idx, :], ysub[tr_idx])\n",
      "        ypred = clf.predict(Xsub[ts_idx, :])\n",
      "        tp = np.sum(ypred[np.where(yts ==  1)[0]] == 1)\n",
      "        fp = np.sum(ypred[np.where(yts == -1)[0]] == 1)\n",
      "        tn = np.sum(ypred[np.where(yts == -1)[0]] == -1)\n",
      "        Tp[i], Fp[i], Tn[i], Fn[i] = tp, fp, tn, yts.shape[0]-(tp+fp+tn)\n",
      "        sys.stderr.write (\"%d (%d %d %d %d)\"%(i, tp, fp, tn, yts.shape[0]-(tp+fp+tn)))\n",
      "        \n",
      "    Tp_mean, Fp_mean, Tn_mean, Fn_mean = np.mean(Tp), np.mean(Fp), np.mean(Tn), np.mean(Fn)\n",
      "    recall  = Tp_mean / (Tp_mean + Fn_mean)\n",
      "    prec = Tp_mean / (Tp_mean + Fp_mean)\n",
      "    f1score = 2*Tp_mean/(2*Tp_mean + Fp_mean + Fn_mean)\n",
      "    sys.stderr.write('\\nAverage: Prec=%.3f  Recall=%.3f   F1-score=%.3f\\n'%(prec, recall, f1score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Size = 1000  ==> 0 (269 231 0 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "1 (251 249 0 0)2 (265 235 0 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "3 (271 229 0 0)4 (263 237 0 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Average: Prec=0.528  Recall=1.000   F1-score=0.691\n",
        "\n",
        "Size = 2000  ==> "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "0 (549 451 0 0)1 (549 451 0 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2 (542 458 0 0)3 (539 461 0 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "4 (550 450 0 0)\n",
        "Average: Prec=0.546  Recall=1.000   F1-score=0.706\n",
        "\n",
        "Size = 4000  ==> "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "0 (234 71 886 809)1 (255 89 896 760)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2 (276 77 910 737)3 (210 60 893 837)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "4 (295 97 898 710)\n",
        "Average: Prec=0.763  Recall=0.248   F1-score=0.374\n",
        "\n",
        "Size = 8000  ==> "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "0 (514 103 1773 1610)1 (527 106 1807 1560)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2 (706 165 1779 1350)3 (573 133 1787 1507)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "4 (531 131 1799 1539)\n",
        "Average: Prec=0.817  Recall=0.274   F1-score=0.410\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-151-0a71d38fddc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mXsub\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mysub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadRandomSample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/home/vahid/Downloads/data/ml/data_train.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoodfeat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgoodfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mysub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mysub\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m156\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-149-1a123f2c8060>\u001b[0m in \u001b[0;36mreadRandomSample\u001b[1;34m(data_fname, y, size, goodfeat, acc_miny, acc_maxy)\u001b[0m\n\u001b[0;32m     35\u001b[0m                     \u001b[0mix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgoodfeat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m                             \u001b[0mix\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                             \u001b[0mXsub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Apply Logistic Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.linear_model\n",
      "\n",
      "# we create an instance of Neighbours Classifier and fit the data.\n",
      "n=20000\n",
      "Xsub, ysub = readRandomSample('/home/vahid/Downloads/data/ml/data_train.txt', y[0], size=n, goodfeat=goodfeatures)\n",
      "\n",
      "ysub[np.where(ysub <= 156)[0]] = -1\n",
      "ysub[np.where(ysub  > 156)[0]] =  1\n",
      "Xsub = (Xsub - np.mean(Xsub, axis=0)) / np.std(Xsub, axis=0)\n",
      "\n",
      "tr_idx = np.random.choice(n, size=n/2, replace=False)\n",
      "ts_idx = np.setdiff1d(np.arange(n), tr_idx, assume_unique=True)\n",
      "yts = ysub[ts_idx]\n",
      "\n",
      "for c in [1.0, 10.0, 100.0, 1000.0, 10000.0]:\n",
      "    logreg = sklearn.linear_model.LogisticRegression(C=c)\n",
      "    logreg.fit(Xsub[tr_idx,:], ysub[tr_idx])\n",
      "    ypred = logreg.predict(Xsub[ts_idx])\n",
      "    prec, recall, f1score = evalPerformance(yts, ypred)\n",
      "    print (\"C=%.4f ==> Prec:%.3f  Recall:%.3f  F1Score:%.3f\"%(c, prec, recall, f1score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "4146 1809 2912 1133\n",
        "4146 1808 2913 1133\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C=1.0000 Gamma=1.0000  ==> Prec:0.696  Recall:0.785  F1Score:0.738\n",
        "C=10.0000 Gamma=1.0000  ==> Prec:0.696  Recall:0.785  F1Score:0.738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=100.0000 Gamma=1.0000  ==> Prec:0.696  Recall:0.785  F1Score:0.738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "4145 1808 2913 1134\n",
        "4145 1808 2913 1134\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=1000.0000 Gamma=1.0000  ==> Prec:0.696  Recall:0.785  F1Score:0.738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=10000.0000 Gamma=1.0000  ==> Prec:0.696  Recall:0.785  F1Score:0.738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "4145 1808 2913 1134\n"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Classify subclasses 156:164 \n",
      "\n",
      "**positive (+1): y==163:164**\n",
      "\n",
      "**negative (-1):  156 <= y <= 162**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Find good features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rdiff2 = calStandMeanDiff(y, np.arange(157,162), np.arange(162, 165))\n",
      "\n",
      "print(np.sum(rdiff2 > 0.1))\n",
      "goodfeatures_cs2 = np.where(rdiff2 > 0.1)[0]\n",
      "\n",
      "goodfeatures_cs2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "335\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Number of samples in NegClass: 235201 and PosClass: 287574 \n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 110,
       "text": [
        "array([  1,   2,   5,   6,   7,   8,  13,  15,  16,  17,  18,  20,  24,\n",
        "        25,  28,  31,  34,  35,  37,  38,  40,  43,  48,  50,  51,  52,\n",
        "        56,  57,  59,  61,  65,  69,  70,  71,  72,  79,  81,  84,  87,\n",
        "        90,  91,  92,  94,  97,  99, 101, 106, 110, 112, 118, 122, 127,\n",
        "       129, 133, 138, 139, 141, 143, 146, 148, 149, 151, 152, 153, 155,\n",
        "       158, 161, 163, 166, 167, 169, 175, 178, 179, 183, 184, 187, 188,\n",
        "       189, 196, 206, 208, 210, 217, 219, 221, 222, 224, 226, 229, 230,\n",
        "       237, 239, 246, 250, 253, 255, 256, 258, 261, 263, 267, 271, 272,\n",
        "       274, 277, 281, 287, 288, 289, 293, 294, 295, 305, 307, 308, 311,\n",
        "       313, 315, 316, 318, 320, 324, 328, 329, 330, 332, 334, 337, 338,\n",
        "       342, 343, 344, 348, 350, 353, 355, 357, 358, 359, 364, 366, 367,\n",
        "       372, 374, 381, 386, 388, 397, 400, 401, 402, 403, 404, 406, 407,\n",
        "       408, 409, 412, 413, 414, 416, 418, 419, 422, 428, 430, 432, 437,\n",
        "       440, 443, 445, 451, 457, 462, 464, 466, 467, 468, 470, 471, 473,\n",
        "       476, 484, 485, 486, 490, 492, 496, 498, 499, 500, 501, 504, 507,\n",
        "       510, 511, 516, 517, 524, 526, 528, 529, 530, 537, 539, 540, 541,\n",
        "       547, 548, 553, 556, 561, 564, 565, 566, 572, 576, 578, 579, 581,\n",
        "       582, 583, 585, 588, 590, 594, 600, 601, 602, 603, 605, 607, 608,\n",
        "       609, 610, 613, 615, 617, 628, 632, 633, 634, 641, 643, 645, 648,\n",
        "       651, 652, 653, 655, 656, 658, 661, 665, 666, 667, 669, 671, 673,\n",
        "       680, 681, 686, 692, 700, 701, 703, 711, 712, 714, 715, 716, 718,\n",
        "       719, 722, 723, 724, 726, 727, 728, 732, 735, 748, 751, 753, 757,\n",
        "       758, 759, 760, 762, 764, 770, 772, 773, 774, 775, 776, 778, 784,\n",
        "       785, 786, 790, 793, 794, 796, 798, 802, 806, 811, 815, 816, 817,\n",
        "       822, 823, 829, 833, 840, 848, 849, 852, 853, 854, 855, 858, 863,\n",
        "       864, 869, 871, 876, 884, 886, 890, 893, 894, 897])"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xsub, ysub = readRandomSample('/home/vahid/Downloads/data/ml/data_train.txt', y[0], size=20000, acc_miny=156, acc_maxy=164)\n",
      "\n",
      "ysub[np.where(ysub <= 162)[0]] = -1\n",
      "ysub[np.where(ysub  > 162)[0]] =  1\n",
      "\n",
      "Xsub = Xsub[:, goodfeatures]\n",
      "Xsub = (Xsub - np.mean(Xsub)) / np.std(Xsub)\n",
      "\n",
      "Xsub.shape\n",
      "\n",
      "ntot = Xsub.shape[0]\n",
      "tr_idx = np.random.choice(ntot, size=ntot/2, replace=False)\n",
      "ts_idx = np.setdiff1d(np.arange(ntot), tr_idx, assume_unique=True)\n",
      "yts = ysub[ts_idx]\n",
      "\n",
      "for c in [0.0001, 0.001, 0.01, 0.1, 1.0]:\n",
      "    for gm in [0.001, 0.01, 0.1, 1.0]:\n",
      "        clf = sklearn.svm.SVC(C=c, kernel='rbf', gamma=gm)\n",
      "        clf.fit(Xsub[tr_idx, :], ysub[tr_idx])\n",
      "        ypred = clf.predict(Xsub[ts_idx, :])\n",
      "        tp = np.sum(ypred[np.where(yts ==  1)[0]] == 1)\n",
      "        fp = np.sum(ypred[np.where(yts == -1)[0]] == 1)\n",
      "        tn = np.sum(ypred[np.where(yts == -1)[0]] == -1)\n",
      "        print (\"C=%.4f Gamma=%.4f  ==> TP:%d  FP:%d  TN:%d FN:%d\"%(c, gm, tp, fp, tn, yts.shape[0]-(tp+fp+tn)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "array([[-0.25956771,  1.89171015, -0.25956771,  0.81607122],\n",
        "       [-0.25956771, -0.25956771, -0.25956771,  0.0989786 ],\n",
        "       [-0.25956771,  0.0989786 , -0.25956771, -0.25956771]])"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = ['1', '2', '3']\n",
      "\n",
      "np.array(a).astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 135,
       "text": [
        "array([1, 2, 3])"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xtest = pandas.read_table('/home/vahid/Downloads/data/ml/data_test.txt', sep=\" \", usecols=goodfeatures, dtype='int', header=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xtest.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 138,
       "text": [
        "(262102, 332)"
       ]
      }
     ],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xtest[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>14</th>\n",
        "      <th>15</th>\n",
        "      <th>24</th>\n",
        "      <th>25</th>\n",
        "      <th>35</th>\n",
        "      <th>38</th>\n",
        "      <th>...</th>\n",
        "      <th>876</th>\n",
        "      <th>877</th>\n",
        "      <th>878</th>\n",
        "      <th>879</th>\n",
        "      <th>881</th>\n",
        "      <th>884</th>\n",
        "      <th>886</th>\n",
        "      <th>890</th>\n",
        "      <th>892</th>\n",
        "      <th>894</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>...</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>6</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>0</td>\n",
        "      <td>9</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 332 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 139,
       "text": [
        "   1    2    5    6    14   15   24   25   35   38  ...   876  877  878  879  \\\n",
        "0    0    0    0    0    0    0    3    2    0    0 ...     0    0    3    0   \n",
        "1    1    0    0    0    0    1    0    0    0    0 ...     0    0    0    0   \n",
        "2    5    0    4    0    4    0    0    0    0    1 ...     0    0    3    6   \n",
        "3    0    3    0    0    0    0    0    0    0    0 ...     2    0    3    0   \n",
        "4    0    9    0    0    0    1    3    0    0    0 ...     2    0    3    0   \n",
        "\n",
        "   881  884  886  890  892  894  \n",
        "0    0    0    0    0    2    0  \n",
        "1    1    1    1    1    0    0  \n",
        "2    0    0    0    0    1    1  \n",
        "3    0    0    0    0    0    1  \n",
        "4    0    0    0    0    0    1  \n",
        "\n",
        "[5 rows x 332 columns]"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Extracting the Lower Half ($y \\in [1..156]$)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "yuniq,ycount = np.unique(y[0][np.where(y[0]<=156)[0]], return_counts=True)\n",
      "\n",
      "print(ycount)\n",
      "np.sum(ycount[np.where(yuniq<=130)[0]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1263  1261  1255  1256  1252  1235  1240  1264  1256  1281  1245  1278\n",
        "  1278  1253  1255  1255  1291  1277  1308  1285  1322  1309  1318  1322\n",
        "  1327  1339  1361  1361  1335  1396  1359  1393  1373  1356  1398  1416\n",
        "  1386  1398  1396  1404  1430  1398  1416  1406  1420  1445  1433  1445\n",
        "  1454  1451  1481  1482  1477  1474  1478  1486  1512  1492  1557  1557\n",
        "  1548  1530  1574  1582  1606  1611  1666  1650  1704  1739  1735  1743\n",
        "  1728  1796  1737  1810  1822  1864  1847  1838  1857  1913  1910  1917\n",
        "  2006  1992  2033  2063  2072  2063  2096  2128  2134  2206  2215  2212\n",
        "  2258  2279  2287  2319  2356  2435  2438  2491  2486  2485  2502  2555\n",
        "  2594  2629  2575  2587  2777  2875  2897  2884  2978  3087  3179  3368\n",
        "  3388  3421  3409  3453  3536  3586  3615  3696  3821  3802  3934  4059\n",
        "  4069  4253  4819  4939  5038  5259  5310  6080  6487  6623  7256  8279\n",
        "  9069  9221  9707  9998 10557 10645 11484 12382 12858 16548 18562 21943]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "247846"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('/home/vahid/Downloads/data/ml/data_train.txt', 'r') as fp:\n",
      "    with open('../data/data_tr.lower.txt', 'w') as f1, open('../data/label_tr.lower.txt', 'w') as g1, \\\n",
      "         open('../data/data_cv.lower.txt', 'w') as f2, open('../data/label_cv.lower.txt', 'w') as g2:\n",
      "        n = 0\n",
      "        for line in fp:\n",
      "            if y[0][n] <= 156:\n",
      "                if np.random.uniform(low=0, high=1, size=None) > 0.1:\n",
      "                    f1.write('%s'%line)\n",
      "                    g1.write('%d %d\\n'%(n, y[0][n]))\n",
      "                else:\n",
      "                    f2.write('%s'%line)\n",
      "                    g2.write('%d %d\\n'%(n, y[0][n]))               \n",
      "            n += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ylow = pandas.read_table(\"../data/label_tr.lower.txt\", sep=\" \", dtype='int', header=None)\n",
      "\n",
      "np.unique(ylow[1], return_counts=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
        "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
        "         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
        "         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
        "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
        "        105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
        "        118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
        "        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
        "        144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156]),\n",
        " array([ 1104,  1123,  1120,  1137,  1110,  1113,  1101,  1149,  1122,\n",
        "         1153,  1120,  1155,  1145,  1139,  1134,  1137,  1177,  1153,\n",
        "         1173,  1135,  1190,  1165,  1196,  1205,  1209,  1211,  1226,\n",
        "         1220,  1219,  1255,  1215,  1253,  1237,  1203,  1248,  1282,\n",
        "         1252,  1249,  1246,  1244,  1294,  1261,  1268,  1245,  1281,\n",
        "         1314,  1273,  1290,  1304,  1303,  1347,  1309,  1332,  1326,\n",
        "         1323,  1345,  1384,  1320,  1384,  1400,  1388,  1405,  1424,\n",
        "         1412,  1440,  1447,  1488,  1499,  1537,  1571,  1554,  1573,\n",
        "         1564,  1626,  1565,  1623,  1622,  1669,  1672,  1660,  1683,\n",
        "         1715,  1715,  1723,  1799,  1766,  1808,  1867,  1862,  1834,\n",
        "         1893,  1914,  1931,  1970,  2020,  1988,  2059,  2047,  2066,\n",
        "         2063,  2120,  2179,  2233,  2230,  2247,  2253,  2254,  2327,\n",
        "         2322,  2387,  2306,  2344,  2501,  2609,  2619,  2574,  2687,\n",
        "         2794,  2850,  3051,  3032,  3099,  3087,  3122,  3162,  3211,\n",
        "         3243,  3314,  3445,  3415,  3536,  3667,  3659,  3790,  4291,\n",
        "         4433,  4519,  4754,  4783,  5450,  5860,  5956,  6528,  7420,\n",
        "         8186,  8281,  8729,  8974,  9529,  9596, 10401, 11195, 11583,\n",
        "        14908, 16727, 19731]))"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ylow = pandas.read_table(\"../data/label_cv.lower.txt\", sep=\" \", dtype='int', header=None)\n",
      "\n",
      "np.unique(ylow[1], return_counts=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
        "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
        "         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
        "         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
        "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
        "        105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
        "        118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
        "        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
        "        144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156]),\n",
        " array([ 159,  138,  135,  119,  142,  122,  139,  115,  134,  128,  125,\n",
        "         123,  133,  114,  121,  118,  114,  124,  135,  150,  132,  144,\n",
        "         122,  117,  118,  128,  135,  141,  116,  141,  144,  140,  136,\n",
        "         153,  150,  134,  134,  149,  150,  160,  136,  137,  148,  161,\n",
        "         139,  131,  160,  155,  150,  148,  134,  173,  145,  148,  155,\n",
        "         141,  128,  172,  173,  157,  160,  125,  150,  170,  166,  164,\n",
        "         178,  151,  167,  168,  181,  170,  164,  170,  172,  187,  200,\n",
        "         195,  175,  178,  174,  198,  195,  194,  207,  226,  225,  196,\n",
        "         210,  229,  203,  214,  203,  236,  195,  224,  199,  232,  221,\n",
        "         256,  236,  256,  205,  261,  239,  232,  248,  228,  272,  242,\n",
        "         269,  243,  276,  266,  278,  310,  291,  293,  329,  317,  356,\n",
        "         322,  322,  331,  374,  375,  372,  382,  376,  387,  398,  392,\n",
        "         410,  463,  528,  506,  519,  505,  527,  630,  627,  667,  728,\n",
        "         859,  883,  940,  978, 1024, 1028, 1049, 1083, 1187, 1275, 1640,\n",
        "        1835, 2212]))"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Extracting 157-159"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('/home/vahid/Downloads/data/ml/data_train.txt', 'r') as fp:\n",
      "    with open('../data/data_c157-159.txt', 'w') as f1, open('../data/label_c157-159.txt', 'w') as g1:\n",
      "        n = 0\n",
      "        for line in fp:\n",
      "            if y[0][n] >= 157 and y[0][n] <= 159:\n",
      "                f1.write('%s'%line)\n",
      "                g1.write('%d %d\\n'%(n, y[0][n]))\n",
      "            n += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}