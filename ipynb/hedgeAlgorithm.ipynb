{
 "metadata": {
  "name": "",
  "signature": "sha256:0cb2d67db5700d239e4c03a5212670fc51742d16349fbc6d524eb8082f8c940a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Implementing Hedge Algorithm for Ensemble Learning\n",
      "==============\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our goal is to given prediction results from m experts (classifiers), combine them with weights in such way to get as close as possible to the best classifer. \n",
      "\n",
      "We do that by first initializing all the weights to 1, then iterating throught the results and in cases where the weighted sum of classifiers' prediction does not match with the ground-truth label, we remove the weith of those classifiers who caused this mistake by a multiplicative approach:\n",
      "\n",
      "$w_i = w_i * exp(-\\eta)$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas\n",
      "import scipy, scipy.spatial\n",
      "import sklearn\n",
      "import sys\n",
      "\n",
      "from matplotlib import pyplot as plt\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ycv = pandas.read_table('../data/label_cv.txt', header=None, sep=' ')\n",
      "\n",
      "ycv.iloc[np.where(ycv[0] < 157)[0],0] = -1\n",
      "ycv.iloc[np.where(ycv[0] >=157)[0],0] = 1\n",
      "\n",
      "print(ycv.shape)\n",
      "\n",
      "ycv.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(100000, 1)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>-1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "   0\n",
        "0  1\n",
        "1  1\n",
        "2  1\n",
        "3  1\n",
        "4 -1"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ncol = pandas.read_table('../results/hf1/res_cv.dat', header=None, sep=' ', nrows=3).shape[1]\n",
      "\n",
      "pandas.read_table('../results/hf1/res_cv.dat', header=None, sep=' ', nrows=3).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "      <th>...</th>\n",
        "      <th>1605</th>\n",
        "      <th>1606</th>\n",
        "      <th>1607</th>\n",
        "      <th>1608</th>\n",
        "      <th>1609</th>\n",
        "      <th>1610</th>\n",
        "      <th>1611</th>\n",
        "      <th>1612</th>\n",
        "      <th>1613</th>\n",
        "      <th>1614</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>...</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>...</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>...</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>3 rows \u00d7 1615 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "   0     1     2     3     4     5     6     7     8     9     ...   1605  \\\n",
        "0     1     1     1     1     1     1     1     1     1     1  ...      1   \n",
        "1     1     1     1     1     1     1     1     1     1     1  ...      1   \n",
        "2     1     1     1     1     1     1     1     1     1     1  ...      1   \n",
        "\n",
        "   1606  1607  1608  1609  1610  1611  1612  1613  1614  \n",
        "0     1     1     1     1     1     1     1     1     1  \n",
        "1     1     1     1     1     1     1     1     1     1  \n",
        "2     1     1     1     1     1     1     1     1     1  \n",
        "\n",
        "[3 rows x 1615 columns]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Chunk size to read the table of predictions:\n",
      "chunks = 10000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Weighted Ensemble of Classifiers with Hedge Updating Algorithm"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights = np.ones(shape=ncol, dtype=float)\n",
      "\n",
      "learn_rate = np.exp(-1)\n",
      "\n",
      "n = 0\n",
      "num_mistakes = 0\n",
      "for df in pandas.read_table('../results/hf1/res_cv.dat', header=None, sep=' ', iterator=True, chunksize=chunks):\n",
      "    sys.stdout.write(\"%d %d,%d  ==> Num. of Mistakes: \"%(n, df.shape[0], df.shape[1]))\n",
      "    for i in range(df.shape[0]):\n",
      "        row = df.iloc[i,:]\n",
      "        wsum = np.sum(weights * row)\n",
      "        yi = ycv.iloc[n,0]\n",
      "        if wsum * yi < 0:\n",
      "            num_mistakes += 1\n",
      "            for j,vj in enumerate(row):\n",
      "                if (vj * yi) < 0:\n",
      "                    weights[j] *= learn_rate\n",
      "            \n",
      "        n += 1\n",
      "    print(num_mistakes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 10000,1615  ==> Num. of Mistakes: 837"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "837\n",
        "20000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "837\n",
        "30000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "837\n",
        "40000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "837\n",
        "50000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "837\n",
        "60000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "837\n",
        "70000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "837\n",
        "80000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "837\n",
        "90000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "837\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### What if no updating: naive majority votes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = 0\n",
      "num_mistakes = 0\n",
      "for df in pandas.read_table('../results/hf1/res_cv.dat', header=None, sep=' ', iterator=True, chunksize=chunks):\n",
      "    sys.stdout.write(\"%5d %5d,%d  ==> Num. of Mistakes: \"%(n, df.shape[0], df.shape[1]))\n",
      "    for i in range(df.shape[0]):\n",
      "        row = df.iloc[i,:]\n",
      "        wsum = np.sum(row)\n",
      "        yi = ycv.iloc[n,0]\n",
      "        if wsum * yi < 0:\n",
      "            num_mistakes += 1            \n",
      "        n += 1\n",
      "    print(num_mistakes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "    0 10000,1615  ==> Num. of Mistakes: 2719"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5439\n",
        "20000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8162\n",
        "30000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10839\n",
        "40000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13569\n",
        "50000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "16283\n",
        "60000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "19034\n",
        "70000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "21776\n",
        "80000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "24481\n",
        "90000 10000,1615  ==> Num. of Mistakes: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "27225\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a result of weights updating, during the first 10000 samples, the weights were adjusted and after that no more mistakes were made. While on the other hand, simply taking the majority votes without updating the weiths will result in cumulativly increasing the number of mis-classified items, reaching to 27225 mistakes out of 100000."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}