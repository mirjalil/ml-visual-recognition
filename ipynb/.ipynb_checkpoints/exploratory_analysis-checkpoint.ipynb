{
 "metadata": {
  "name": "",
  "signature": "sha256:10b62c0d0c4a6475d3ed8500c0c85d216d911481aae43224d4975e34671b091e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas\n",
      "import scipy, scipy.spatial\n",
      "import sklearn\n",
      "import sys\n",
      "\n",
      "from matplotlib import pyplot as plt\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = pandas.read_table(\"~/Downloads/data/ml/label_train.txt\", sep=\" \", dtype='int', header=None)\n",
      "\n",
      "y.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>161</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>163</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>56</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>119</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>138</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "     0\n",
        "0  161\n",
        "1  163\n",
        "2   56\n",
        "3  119\n",
        "4  138"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.unique(y[0], return_counts=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
        "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
        "         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
        "         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
        "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
        "        105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
        "        118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
        "        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
        "        144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
        "        157, 158, 159, 160, 161, 162, 163, 164]),\n",
        " array([  1263,   1261,   1255,   1256,   1252,   1235,   1240,   1264,\n",
        "          1256,   1281,   1245,   1278,   1278,   1253,   1255,   1255,\n",
        "          1291,   1277,   1308,   1285,   1322,   1309,   1318,   1322,\n",
        "          1327,   1339,   1361,   1361,   1335,   1396,   1359,   1393,\n",
        "          1373,   1356,   1398,   1416,   1386,   1398,   1396,   1404,\n",
        "          1430,   1398,   1416,   1406,   1420,   1445,   1433,   1445,\n",
        "          1454,   1451,   1481,   1482,   1477,   1474,   1478,   1486,\n",
        "          1512,   1492,   1557,   1557,   1548,   1530,   1574,   1582,\n",
        "          1606,   1611,   1666,   1650,   1704,   1739,   1735,   1743,\n",
        "          1728,   1796,   1737,   1810,   1822,   1864,   1847,   1838,\n",
        "          1857,   1913,   1910,   1917,   2006,   1992,   2033,   2063,\n",
        "          2072,   2063,   2096,   2128,   2134,   2206,   2215,   2212,\n",
        "          2258,   2279,   2287,   2319,   2356,   2435,   2438,   2491,\n",
        "          2486,   2485,   2502,   2555,   2594,   2629,   2575,   2587,\n",
        "          2777,   2875,   2897,   2884,   2978,   3087,   3179,   3368,\n",
        "          3388,   3421,   3409,   3453,   3536,   3586,   3615,   3696,\n",
        "          3821,   3802,   3934,   4059,   4069,   4253,   4819,   4939,\n",
        "          5038,   5259,   5310,   6080,   6487,   6623,   7256,   8279,\n",
        "          9069,   9221,   9707,   9998,  10557,  10645,  11484,  12382,\n",
        "         12858,  16548,  18562,  21943,  30679,  34092,  45439,  60513,\n",
        "         64478,  65211,  92241, 130122]))"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(y[0] > 156)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "522775"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Cal Mean and Var. of each feature for each class\n",
      "\n",
      "ndim = 900\n",
      "def calClassStat(data_fname, y):\n",
      "    \"\"\" Return a dictionary: class_label:(mean_vec, var_vec, num)\n",
      "        data_fname is the file containing all the features and samples\n",
      "        y: class labels for each sample\n",
      "    \"\"\"\n",
      "    clstat={}\n",
      "    yuniq = np.unique(y)\n",
      "    for ci in yuniq:\n",
      "        clstat[ci] = [np.zeros(shape=ndim), np.zeros(shape=ndim), 0]\n",
      "        clstat['all'] = [np.zeros(shape=ndim), np.zeros(shape=ndim), 0]\n",
      "    \n",
      "    with open(data_fname, 'r') as fp:\n",
      "        n = 0\n",
      "        for line in fp:\n",
      "            line = line.strip().split()\n",
      "            vals = np.empty(shape=ndim, dtype=int)\n",
      "            for i,v in enumerate(line):\n",
      "                vals[i] = int(v)            \n",
      "            label = y[n]\n",
      "            assert(len(line) == ndim)\n",
      "            clstat[label][0] += vals\n",
      "            clstat[label][1] += vals**2\n",
      "            clstat[label][2] += 1\n",
      "            n += 1\n",
      "            \n",
      "    \n",
      "    for ci in yuniq:\n",
      "        clstat['all'][0] += clstat[ci][0]\n",
      "        clstat['all'][1] += clstat[ci][1]\n",
      "        clstat['all'][2] += clstat[ci][2]\n",
      "    \n",
      "            \n",
      "    return (clstat)\n",
      "\n",
      "r = calClassStat('/home/vahid/Downloads/data/ml/data_train.txt', y[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Classify items belonging to first half (1) Second half (-1)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sx  = np.zeros(shape=ndim, dtype=float)\n",
      "ssx = np.zeros(shape=ndim, dtype=float)\n",
      "\n",
      "n1 = np.sum(y[0] <= 156)\n",
      "n2 = np.sum(y[0] >  156)\n",
      "for i in range(1,157):\n",
      "    sx += r[i][0]\n",
      "    ssx += r[i][1]\n",
      "r1_mean = sx / float(n1)\n",
      "r1_var = (ssx - 2*sx*r1_mean + r1_mean**2) / float(n1)\n",
      "\n",
      "sx  = np.zeros(shape=ndim, dtype=float)\n",
      "ssx = np.zeros(shape=ndim, dtype=float)\n",
      "for i in range(157,165):\n",
      "    sx += r[i][0]\n",
      "    ssx += r[i][1]\n",
      "r2_mean = sx / float(n2)\n",
      "r2_var = (ssx - 2*sx*r2_mean + r2_mean**2) / float(n2)\n",
      "\n",
      "tot_mean = r['all'][0] / float(r['all'][2])\n",
      "tot_var  = (r['all'][1] - 2*r['all'][0]*tot_mean + tot_mean**2) / float(r['all'][2])\n",
      "\n",
      "rdiff = (r1_mean - r2_mean) / np.sqrt(tot_var)\n",
      "\n",
      "\n",
      "## Good Features:\n",
      "goodfeatures = np.where(rdiff > 0.1)[0]\n",
      "\n",
      "goodfeatures"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "array([  1,   2,   5,   6,  14,  15,  24,  25,  35,  38,  39,  40,  42,\n",
        "        43,  48,  52,  56,  58,  59,  61,  65,  69,  71,  74,  79,  80,\n",
        "        81,  91,  92,  94,  97,  99, 110, 111, 112, 116, 118, 119, 122,\n",
        "       127, 129, 133, 137, 138, 139, 140, 143, 145, 146, 148, 149, 151,\n",
        "       152, 153, 158, 159, 161, 163, 166, 167, 168, 169, 175, 178, 180,\n",
        "       184, 185, 186, 187, 188, 193, 195, 196, 198, 199, 204, 206, 208,\n",
        "       210, 214, 215, 216, 217, 219, 221, 222, 223, 224, 225, 229, 234,\n",
        "       237, 240, 247, 254, 255, 256, 257, 258, 261, 263, 265, 267, 272,\n",
        "       273, 274, 277, 278, 280, 281, 282, 286, 288, 289, 294, 295, 300,\n",
        "       307, 308, 315, 316, 318, 320, 322, 328, 329, 330, 332, 334, 336,\n",
        "       338, 340, 341, 343, 344, 348, 350, 352, 353, 355, 359, 367, 372,\n",
        "       374, 381, 387, 388, 389, 397, 398, 399, 400, 402, 404, 406, 407,\n",
        "       408, 412, 413, 414, 416, 417, 421, 422, 425, 428, 432, 439, 440,\n",
        "       443, 445, 447, 451, 457, 461, 462, 464, 466, 467, 473, 485, 489,\n",
        "       490, 492, 498, 500, 501, 504, 507, 508, 510, 511, 517, 524, 526,\n",
        "       527, 530, 531, 537, 539, 541, 542, 544, 547, 556, 561, 563, 564,\n",
        "       566, 570, 571, 573, 576, 578, 579, 581, 582, 584, 585, 588, 589,\n",
        "       594, 601, 602, 603, 605, 608, 609, 613, 617, 624, 628, 632, 633,\n",
        "       634, 641, 643, 645, 646, 652, 653, 657, 658, 661, 665, 666, 667,\n",
        "       673, 676, 680, 681, 686, 692, 698, 703, 705, 711, 712, 714, 716,\n",
        "       717, 718, 720, 722, 725, 726, 727, 730, 732, 735, 738, 742, 746,\n",
        "       747, 748, 751, 753, 757, 758, 759, 760, 762, 764, 766, 770, 772,\n",
        "       773, 774, 776, 778, 779, 784, 785, 786, 790, 796, 798, 805, 806,\n",
        "       811, 812, 815, 816, 817, 818, 821, 822, 825, 828, 829, 833, 841,\n",
        "       849, 853, 854, 855, 861, 863, 864, 869, 871, 874, 876, 877, 878,\n",
        "       879, 881, 884, 886, 890, 892, 894])"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Read a Random Sample"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def readRandomSample(data_fname, y, size, accept):\n",
      "    \"\"\" Read a random sample\n",
      "    \"\"\"\n",
      "    Xsub = np.empty(shape=(size,ndim), dtype=float)\n",
      "    ysub = np.zeros(shape=size, dtype=int)\n",
      "\n",
      "    \n",
      "    proba = 1.0 - size/float(y.shape[0])\n",
      "    \n",
      "    with open(data_fname, 'r') as fp:\n",
      "        n = 0\n",
      "        nf = 0\n",
      "        for line in fp:\n",
      "            if np.random.uniform(low=0, high=1) > proba and nf < size:\n",
      "                line = line.strip().split()\n",
      "                for i,v in enumerate(line):\n",
      "                    Xsub[nf,i] = int(v)\n",
      "                ysub[nf] = y[n]\n",
      "\n",
      "                nf += 1\n",
      "            n += 1\n",
      "    return(Xsub, ysub)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xsub, ysub = readRandomSample('/home/vahid/Downloads/data/ml/data_train.txt', y[0], size=20000, accept=False)\n",
      "\n",
      "ysub[np.where(ysub <= 156)[0]] = -1\n",
      "ysub[np.where(ysub  > 156)[0]] =  1\n",
      "\n",
      "Xsub = Xsub[:, goodfeatures]\n",
      "Xsub = (Xsub - np.mean(Xsub)) / np.std(Xsub)\n",
      "\n",
      "Xsub.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "(20000, 332)"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.svm\n",
      "\n",
      "ntot = Xsub.shape[0]\n",
      "tr_idx = np.random.choice(ntot, size=ntot/2, replace=False)\n",
      "ts_idx = np.setdiff1d(np.arange(ntot), tr_idx, assume_unique=True)\n",
      "yts = ysub[ts_idx]\n",
      "\n",
      "for c in [0.0001, 0.001, 0.01, 0.1, 1.0]:\n",
      "    for gm in [0.001, 0.01, 0.1, 1.0]:\n",
      "        clf = sklearn.svm.SVC(C=c, kernel='rbf', gamma=gm)\n",
      "        clf.fit(Xsub[tr_idx, :], ysub[tr_idx])\n",
      "        ypred = clf.predict(Xsub[ts_idx, :])\n",
      "        tp = np.sum(ypred[np.where(yts ==  1)[0]] == 1)\n",
      "        fp = np.sum(ypred[np.where(yts == -1)[0]] == 1)\n",
      "        tn = np.sum(ypred[np.where(yts == -1)[0]] == -1)\n",
      "        print (\"C=%.4f Gamma=%.4f  ==> TP:%d  FP:%d  TN:%d FN:%d\"%(c, gm, tp, fp, tn, yts.shape[0]-(tp+fp+tn)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C=0.0001 Gamma=0.0010  ==> TP:5192  FP:4808  TN:0 FN:0\n",
        "C=0.0001 Gamma=0.0100  ==> TP:5192  FP:4808  TN:0 FN:0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0001 Gamma=0.1000  ==> TP:5192  FP:4808  TN:0 FN:0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0001 Gamma=1.0000  ==> TP:5192  FP:4808  TN:0 FN:0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0010 Gamma=0.0010  ==> TP:5192  FP:4808  TN:0 FN:0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0010 Gamma=0.0100  ==> TP:4854  FP:3545  TN:1263 FN:338"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0010 Gamma=0.1000  ==> TP:5192  FP:4808  TN:0 FN:0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0010 Gamma=1.0000  ==> TP:5192  FP:4808  TN:0 FN:0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0100 Gamma=0.0010  ==> TP:4984  FP:3874  TN:934 FN:208"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0100 Gamma=0.0100  ==> TP:4125  FP:2093  TN:2715 FN:1067"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0100 Gamma=0.1000  ==> TP:2266  FP:603  TN:4205 FN:2926"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0100 Gamma=1.0000  ==> TP:5192  FP:4808  TN:0 FN:0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=0.0010  ==> TP:4416  FP:2452  TN:2356 FN:776"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=0.0100  ==> TP:3997  FP:1807  TN:3001 FN:1195"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=0.1000  ==> TP:2856  FP:872  TN:3936 FN:2336"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=1.0000  ==> TP:5192  FP:4808  TN:0 FN:0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=1.0000 Gamma=0.0010  ==> TP:4299  FP:2121  TN:2687 FN:893"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=1.0000 Gamma=0.0100  ==> TP:4103  FP:1787  TN:3021 FN:1089"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=1.0000 Gamma=0.1000  ==> TP:3291  FP:1117  TN:3691 FN:1901"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=1.0000 Gamma=1.0000  ==> TP:1320  FP:308  TN:4500 FN:3872"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Learning Curve"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Picking the best C and gamma (C=1, gamma=0.1)\n",
      "\n",
      "for n in [1000, 2000, 4000, 8000, 16000, 32000]:\n",
      "    Xsub, ysub = readRandomSample('/home/vahid/Downloads/data/ml/data_train.txt', y[0], size=n, accept=False)\n",
      "\n",
      "    ysub[np.where(ysub <= 156)[0]] = -1\n",
      "    ysub[np.where(ysub  > 156)[0]] =  1\n",
      "\n",
      "    Xsub = Xsub[:, goodfeatures]\n",
      "    Xsub = (Xsub - np.mean(Xsub)) / np.std(Xsub)\n",
      "    \n",
      "    sys.stderr.write('\\nSize = %d  ==> '%(n))\n",
      "    Tp = [0,0,0,0,0]\n",
      "    Fp = [0,0,0,0,0]\n",
      "    Tn = [0,0,0,0,0]\n",
      "    Fn = [0,0,0,0,0]\n",
      "    for i in range(5):\n",
      "        tr_idx = np.random.choice(n, size=n/2, replace=False)\n",
      "        ts_idx = np.setdiff1d(np.arange(n), tr_idx, assume_unique=True)\n",
      "        yts = ysub[ts_idx]\n",
      "\n",
      "        clf = sklearn.svm.SVC(C=1.0, kernel='rbf', gamma=0.10)\n",
      "        clf.fit(Xsub[tr_idx, :], ysub[tr_idx])\n",
      "        ypred = clf.predict(Xsub[ts_idx, :])\n",
      "        tp = np.sum(ypred[np.where(yts ==  1)[0]] == 1)\n",
      "        fp = np.sum(ypred[np.where(yts == -1)[0]] == 1)\n",
      "        tn = np.sum(ypred[np.where(yts == -1)[0]] == -1)\n",
      "        Tp[i], Fp[i], Tn[i], Fn[i] = tp, fp, tn, yts.shape[0]-(tp+fp+tn)\n",
      "        sys.stderr.write (\"%d (%d %d %d %d)\"%(i, tp, fp, tn, yts.shape[0]-(tp+fp+tn)))\n",
      "        \n",
      "    Tp_mean, Fp_mean, Tn_mean, Fn_mean = np.mean(Tp), np.mean(Fp), np.mean(Tn), np.mean(Fn)\n",
      "    tpr  = Tp_mean / (Tp_mean + Fn_mean)\n",
      "    prec = Tp_mean / (Tp_mean + Fp_mean)\n",
      "    sys.stderr.write('\\nAverage: TP=%.3ff FP=%.3f   TN=%.3f FN=%.3f\\n'%(Tp_mean, Fp_mean, Tn_mean, Fn_mean))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Size = 1000  ==> 0 (153 57 191 99)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "1 (155 51 187 107)2 (147 51 184 118)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "3 (150 36 195 119)4 (168 46 172 114)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Average: TP=154.600f FP=48.200   TN=185.800 FN=111.400\n",
        "\n",
        "Size = 2000  ==> "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "0 (326 110 349 215)1 (313 98 361 228)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2 (330 101 369 200)3 (313 103 369 215)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "4 (297 99 389 215)\n",
        "Average: TP=315.800f FP=102.200   TN=367.400 FN=214.600\n",
        "\n",
        "Size = 4000  ==> "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "0 (600 208 763 429)1 (587 193 760 460)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2 (588 202 770 440)3 (561 212 769 458)"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-78-9c58647dc402>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXsub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtr_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mysub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtr_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mypred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXsub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mts_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mypred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myts\u001b[0m \u001b[1;33m==\u001b[0m  \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    229\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a=[1,2,3,4]\n",
      "np.mean(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "2.5"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(ypred == -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "9"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(ysub[ts_idx] == 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "5215"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.std(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "0.81649658092772603"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xsub[1:4, np.array([1,2,3,4])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "array([[-0.25956771,  1.89171015, -0.25956771,  0.81607122],\n",
        "       [-0.25956771, -0.25956771, -0.25956771,  0.0989786 ],\n",
        "       [-0.25956771,  0.0989786 , -0.25956771, -0.25956771]])"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}