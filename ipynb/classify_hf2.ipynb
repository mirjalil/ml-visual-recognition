{
 "metadata": {
  "name": "",
  "signature": "sha256:873bdd3d6998861a66dbf9a0dab86fe35f230df7d80dd8dea7958a4c62ce970c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas\n",
      "import scipy, scipy.spatial\n",
      "import sklearn\n",
      "import sys\n",
      "\n",
      "from matplotlib import pyplot as plt\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = pandas.read_table(\"~/Downloads/data/ml/label_train.txt\", sep=\" \", dtype='int', header=None)\n",
      "\n",
      "ndim= 900\n",
      "y.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>161</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>163</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>56</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>119</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>138</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "     0\n",
        "0  161\n",
        "1  163\n",
        "2   56\n",
        "3  119\n",
        "4  138"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.unique(y[0], return_counts=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
        "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
        "         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
        "         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
        "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
        "        105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
        "        118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
        "        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
        "        144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
        "        157, 158, 159, 160, 161, 162, 163, 164]),\n",
        " array([  1263,   1261,   1255,   1256,   1252,   1235,   1240,   1264,\n",
        "          1256,   1281,   1245,   1278,   1278,   1253,   1255,   1255,\n",
        "          1291,   1277,   1308,   1285,   1322,   1309,   1318,   1322,\n",
        "          1327,   1339,   1361,   1361,   1335,   1396,   1359,   1393,\n",
        "          1373,   1356,   1398,   1416,   1386,   1398,   1396,   1404,\n",
        "          1430,   1398,   1416,   1406,   1420,   1445,   1433,   1445,\n",
        "          1454,   1451,   1481,   1482,   1477,   1474,   1478,   1486,\n",
        "          1512,   1492,   1557,   1557,   1548,   1530,   1574,   1582,\n",
        "          1606,   1611,   1666,   1650,   1704,   1739,   1735,   1743,\n",
        "          1728,   1796,   1737,   1810,   1822,   1864,   1847,   1838,\n",
        "          1857,   1913,   1910,   1917,   2006,   1992,   2033,   2063,\n",
        "          2072,   2063,   2096,   2128,   2134,   2206,   2215,   2212,\n",
        "          2258,   2279,   2287,   2319,   2356,   2435,   2438,   2491,\n",
        "          2486,   2485,   2502,   2555,   2594,   2629,   2575,   2587,\n",
        "          2777,   2875,   2897,   2884,   2978,   3087,   3179,   3368,\n",
        "          3388,   3421,   3409,   3453,   3536,   3586,   3615,   3696,\n",
        "          3821,   3802,   3934,   4059,   4069,   4253,   4819,   4939,\n",
        "          5038,   5259,   5310,   6080,   6487,   6623,   7256,   8279,\n",
        "          9069,   9221,   9707,   9998,  10557,  10645,  11484,  12382,\n",
        "         12858,  16548,  18562,  21943,  30679,  34092,  45439,  60513,\n",
        "         64478,  65211,  92241, 130122]))"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "yuniq,ycount = np.unique(y[0], return_counts=True)\n",
      "\n",
      "print(np.sum(ycount[np.where(np.in1d(yuniq, range(157, 162)))[0]]))\n",
      "print(np.sum(ycount[np.where(np.in1d(yuniq, range(162, 165)))[0]]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "235201\n",
        "287574\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "cstat = pickle.load(open( \"../data/sum_features.dat\", \"rb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "pickle.dump( r, open( \"../data/sum_features.dat\", \"wb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Calclulate Standardized Mean Difference Between Classes\n",
      "\n",
      "def calStandMeanDiff(y, cstat, yneg, ypos):\n",
      "    sx  = np.zeros(shape=ndim, dtype=float)\n",
      "    ssx = np.zeros(shape=ndim, dtype=float)\n",
      "\n",
      "\n",
      "    n1 = np.sum(np.in1d(y, yneg))\n",
      "    n2 = np.sum(np.in1d(y, ypos))\n",
      "    sys.stderr.write(\"Number of samples in NegClass: %d and PosClass: %d \\n\"%(n1, n2))\n",
      "\n",
      "    for yi in yneg:\n",
      "        sx += cstat[yi][0]\n",
      "        ssx += cstat[yi][1]\n",
      "    r1_mean = sx / float(n1)\n",
      "    r1_var = (ssx - 2*sx*r1_mean + r1_mean**2) / float(n1)\n",
      "\n",
      "    sx  = np.zeros(shape=ndim, dtype=float)\n",
      "    ssx = np.zeros(shape=ndim, dtype=float)\n",
      "    for yi in ypos:\n",
      "        sx += cstat[yi][0]\n",
      "        ssx += cstat[yi][1]\n",
      "    r2_mean = sx / float(n2)\n",
      "    r2_var = (ssx - 2*sx*r2_mean + r2_mean**2) / float(n2)\n",
      "\n",
      "    tot_mean = cstat['all'][0] / float(cstat['all'][2])\n",
      "    tot_var  = (cstat['all'][1] - 2*cstat['all'][0]*tot_mean + tot_mean**2) / float(cstat['all'][2])\n",
      "\n",
      "    rdiff = (r1_mean - r2_mean) / np.sqrt(tot_var)\n",
      "\n",
      "    return (rdiff)\n",
      "\n",
      "\n",
      "## unit test:\n",
      "mean_test = calStandMeanDiff(y, cstat, np.arange(157,162), np.arange(162, 165)) \n",
      "print(np.sum(mean_test > 0.1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "335\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Number of samples in NegClass: 235201 and PosClass: 287574 \n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Classify items belonging to first half (1) Second half (-1)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Finding Good Features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rdiff = calStandMeanDiff(y, cstat, np.arange(157,162), np.arange(162, 165))\n",
      "\n",
      "\n",
      "## Good Features:\n",
      "goodfeatures = np.where(rdiff > 0.1)[0]\n",
      "\n",
      "goodfeatures"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Number of samples in NegClass: 235201 and PosClass: 287574 \n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "array([  1,   2,   5,   6,   7,   8,  13,  15,  16,  17,  18,  20,  24,\n",
        "        25,  28,  31,  34,  35,  37,  38,  40,  43,  48,  50,  51,  52,\n",
        "        56,  57,  59,  61,  65,  69,  70,  71,  72,  79,  81,  84,  87,\n",
        "        90,  91,  92,  94,  97,  99, 101, 106, 110, 112, 118, 122, 127,\n",
        "       129, 133, 138, 139, 141, 143, 146, 148, 149, 151, 152, 153, 155,\n",
        "       158, 161, 163, 166, 167, 169, 175, 178, 179, 183, 184, 187, 188,\n",
        "       189, 196, 206, 208, 210, 217, 219, 221, 222, 224, 226, 229, 230,\n",
        "       237, 239, 246, 250, 253, 255, 256, 258, 261, 263, 267, 271, 272,\n",
        "       274, 277, 281, 287, 288, 289, 293, 294, 295, 305, 307, 308, 311,\n",
        "       313, 315, 316, 318, 320, 324, 328, 329, 330, 332, 334, 337, 338,\n",
        "       342, 343, 344, 348, 350, 353, 355, 357, 358, 359, 364, 366, 367,\n",
        "       372, 374, 381, 386, 388, 397, 400, 401, 402, 403, 404, 406, 407,\n",
        "       408, 409, 412, 413, 414, 416, 418, 419, 422, 428, 430, 432, 437,\n",
        "       440, 443, 445, 451, 457, 462, 464, 466, 467, 468, 470, 471, 473,\n",
        "       476, 484, 485, 486, 490, 492, 496, 498, 499, 500, 501, 504, 507,\n",
        "       510, 511, 516, 517, 524, 526, 528, 529, 530, 537, 539, 540, 541,\n",
        "       547, 548, 553, 556, 561, 564, 565, 566, 572, 576, 578, 579, 581,\n",
        "       582, 583, 585, 588, 590, 594, 600, 601, 602, 603, 605, 607, 608,\n",
        "       609, 610, 613, 615, 617, 628, 632, 633, 634, 641, 643, 645, 648,\n",
        "       651, 652, 653, 655, 656, 658, 661, 665, 666, 667, 669, 671, 673,\n",
        "       680, 681, 686, 692, 700, 701, 703, 711, 712, 714, 715, 716, 718,\n",
        "       719, 722, 723, 724, 726, 727, 728, 732, 735, 748, 751, 753, 757,\n",
        "       758, 759, 760, 762, 764, 770, 772, 773, 774, 775, 776, 778, 784,\n",
        "       785, 786, 790, 793, 794, 796, 798, 802, 806, 811, 815, 816, 817,\n",
        "       822, 823, 829, 833, 840, 848, 849, 852, 853, 854, 855, 858, 863,\n",
        "       864, 869, 871, 876, 884, 886, 890, 893, 894, 897])"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Read a Random Sample"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def readRandomSample(data_fname, y, size, goodfeat=None, acc_miny=None, acc_maxy=None):\n",
      "    \"\"\" Read a random sample\n",
      "    \"\"\"\n",
      "    if goodfeat is None:\n",
      "        goodfeat = np.arange(ndim)\n",
      "    Xsub = np.empty(shape=(size,goodfeat.shape[0]), dtype=float)\n",
      "    ysub = np.zeros(shape=size, dtype=int)\n",
      "\n",
      "    if acc_miny is None:\n",
      "        acc_miny = np.min(y)\n",
      "    if acc_maxy is None:\n",
      "        acc_maxy = np.max(y)\n",
      "        \n",
      "    #yuniq, ycount = np.unique(y, return_counts=True)\n",
      "    #tot_acceptable = np.sum(ycount[np.where((yuniq >= acc_miny) & (yuniq <= acc_maxy))[0]])\n",
      "    \n",
      "    acceptable_indx = np.where((y>=acc_miny) & (y<=acc_maxy))[0]\n",
      "    assert(acceptable_indx.shape[0] > size)\n",
      "    choice_indx = np.sort(np.random.choice(acceptable_indx, size, replace=False))\n",
      "    #print(choice_indx.shape)\n",
      "    #sys.stderr.write(\"Total Accetables: --> %d\"%(tot_acceptable))\n",
      "    \n",
      "    #proba = 1.0 - size/float(tot_acceptable)\n",
      "    \n",
      "        \n",
      "    with open(data_fname, 'r') as fp:\n",
      "        n = 0\n",
      "        nf = 0\n",
      "        for line in fp:\n",
      "#            if (y[n] >= acc_miny and y[n]<=acc_maxy):\n",
      "#                if np.random.uniform(low=0, high=1) > proba and nf < size:\n",
      "            if nf < size:\n",
      "                if n == choice_indx[nf]:\n",
      "                    line = line.strip().split()\n",
      "                    ix = -1\n",
      "                    for i,v in enumerate(line):\n",
      "                        if np.any(goodfeat == i):\n",
      "                            ix += 1\n",
      "                            Xsub[nf,ix] = int(v)\n",
      "                    ysub[nf] = y[n]\n",
      "\n",
      "                    nf += 1\n",
      "            n += 1\n",
      "    return(Xsub, ysub)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## unit testing readRandomSample()\n",
      "gf_test = np.arange(18,27)\n",
      "Xsub, ysub = readRandomSample('/home/vahid/Downloads/data/ml/data_train.txt', y[0], \\\n",
      "                              size=2000, goodfeat=gf_test, acc_miny=15, acc_maxy=20)\n",
      "\n",
      "print(Xsub.shape)\n",
      "print(np.unique(ysub))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(2000, 9)\n",
        "[15 16 17 18 19 20]\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Performance Evaluation\n",
      "def evalPerformance(ytrue, ypred):\n",
      "    tp = np.sum(ypred[np.where(ytrue ==  1)[0]] == 1)\n",
      "    fp = np.sum(ypred[np.where(ytrue == -1)[0]] == 1)\n",
      "    tn = np.sum(ypred[np.where(ytrue == -1)[0]] == -1)\n",
      "    fn = ytrue.shape[0]-(tp+fp+tn)\n",
      "    #sys.stderr.write('%d %d %d %d\\n'%(tp,fp,tn,fn))\n",
      "    prec = tp / float(tp + fp)\n",
      "    recall  = tp / float(tp + fn)\n",
      "    f1score = 2*tp/float(2*tp + fp + fn)\n",
      "\n",
      "    return (prec, recall, f1score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xsub, ysub = readRandomSample('/home/vahid/Downloads/data/ml/data_train.txt', y[0], size=20000, \\\n",
      "                              goodfeat=goodfeatures, acc_miny=157, acc_maxy=164)\n",
      "\n",
      "assert(np.sum(ysub < 157) == 0)\n",
      "ysub[np.where(ysub < 162)[0]] = -1\n",
      "ysub[np.where(ysub >= 162)[0]] =  1\n",
      "\n",
      "print(np.sum(ysub == -1), np.sum(ysub==1))\n",
      "\n",
      "#Xsub = Xsub[:, goodfeatures]\n",
      "Xsub = (Xsub - np.mean(Xsub, axis=0)) / np.std(Xsub, axis=0)\n",
      "\n",
      "Xsub.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(8907, 11093)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "(20000, 335)"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.svm\n",
      "\n",
      "ntot = Xsub.shape[0]\n",
      "tr_idx = np.random.choice(ntot, size=ntot/2, replace=False)\n",
      "ts_idx = np.setdiff1d(np.arange(ntot), tr_idx, assume_unique=True)\n",
      "yts = ysub[ts_idx]\n",
      "\n",
      "for c in [0.0001, 0.001, 0.01, 0.1, 1.0]:\n",
      "    for gm in [0.001, 0.01, 0.1, 1.0]:\n",
      "        clf = sklearn.svm.SVC(C=c, kernel='rbf', gamma=gm)\n",
      "        clf.fit(Xsub[tr_idx, :], ysub[tr_idx])\n",
      "        ypred = clf.predict(Xsub[ts_idx, :])\n",
      "        prec, recall, f1score = evalPerformance(yts, ypred)\n",
      "        print (\"C=%.4f Gamma=%.4f  ==> Prec:%.3f  Recall:%.3f  F1Score:%.3f\"%(c, gm, prec, recall, f1score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C=0.0001 Gamma=0.0010  ==> Prec:0.550  Recall:1.000  F1Score:0.710\n",
        "C=0.0001 Gamma=0.0100  ==> Prec:0.550  Recall:1.000  F1Score:0.710"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0001 Gamma=0.1000  ==> Prec:0.550  Recall:1.000  F1Score:0.710"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0001 Gamma=1.0000  ==> Prec:0.550  Recall:1.000  F1Score:0.710"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0010 Gamma=0.0010  ==> Prec:0.550  Recall:1.000  F1Score:0.710"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0010 Gamma=0.0100  ==> Prec:0.550  Recall:1.000  F1Score:0.710"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0010 Gamma=0.1000  ==> Prec:0.550  Recall:1.000  F1Score:0.710"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0010 Gamma=1.0000  ==> Prec:0.550  Recall:1.000  F1Score:0.710"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0100 Gamma=0.0010  ==> Prec:0.637  Recall:0.862  F1Score:0.732"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0100 Gamma=0.0100  ==> Prec:0.732  Recall:0.451  F1Score:0.558"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0100 Gamma=0.1000  ==> Prec:0.550  Recall:1.000  F1Score:0.710"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0100 Gamma=1.0000  ==> Prec:0.550  Recall:1.000  F1Score:0.710"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=0.0010  ==> Prec:0.663  Recall:0.832  F1Score:0.738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=0.0100  ==> Prec:0.717  Recall:0.591  F1Score:0.648"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=0.1000  ==> Prec:0.550  Recall:1.000  F1Score:0.710"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=1.0000  ==> Prec:0.550  Recall:1.000  F1Score:0.710"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=1.0000 Gamma=0.0010  ==> Prec:0.675  Recall:0.827  F1Score:0.743"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=1.0000 Gamma=0.0100  ==> Prec:0.708  Recall:0.698  F1Score:0.703"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=1.0000 Gamma=0.1000  ==> Prec:0.550  Recall:1.000  F1Score:0.710"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=1.0000 Gamma=1.0000  ==> Prec:0.550  Recall:1.000  F1Score:0.709"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Fine-grid search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.svm\n",
      "\n",
      "ntot = Xsub.shape[0]\n",
      "tr_idx = np.random.choice(ntot, size=ntot/2, replace=False)\n",
      "ts_idx = np.setdiff1d(np.arange(ntot), tr_idx, assume_unique=True)\n",
      "yts = ysub[ts_idx]\n",
      "\n",
      "for c in [0.05, 0.10, 0.15, 0.25, 0.5, 0.8]:\n",
      "    for gm in [0.0005, 0.001, 0.0015, 0.002, 0.005]:\n",
      "        clf = sklearn.svm.SVC(C=c, kernel='rbf', gamma=gm)\n",
      "        clf.fit(Xsub[tr_idx, :], ysub[tr_idx])\n",
      "        ypred = clf.predict(Xsub[ts_idx, :])\n",
      "        prec, recall, f1score = evalPerformance(yts, ypred)\n",
      "        print (\"C=%.4f Gamma=%.4f  ==> Prec:%.3f  Recall:%.3f  F1Score:%.3f\"%(c, gm, prec, recall, f1score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C=0.0500 Gamma=0.0005  ==> Prec:0.636  Recall:0.869  F1Score:0.734\n",
        "C=0.0500 Gamma=0.0010  ==> Prec:0.646  Recall:0.842  F1Score:0.731"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0500 Gamma=0.0015  ==> Prec:0.651  Recall:0.822  F1Score:0.727"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0500 Gamma=0.0020  ==> Prec:0.655  Recall:0.804  F1Score:0.722"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.0500 Gamma=0.0050  ==> Prec:0.675  Recall:0.714  F1Score:0.694"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=0.0005  ==> Prec:0.643  Recall:0.858  F1Score:0.735"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=0.0010  ==> Prec:0.653  Recall:0.836  F1Score:0.733"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=0.0015  ==> Prec:0.658  Recall:0.820  F1Score:0.730"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=0.0020  ==> Prec:0.662  Recall:0.803  F1Score:0.726"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1000 Gamma=0.0050  ==> Prec:0.675  Recall:0.721  F1Score:0.697"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1500 Gamma=0.0005  ==> Prec:0.648  Recall:0.855  F1Score:0.737"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1500 Gamma=0.0010  ==> Prec:0.656  Recall:0.833  F1Score:0.734"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1500 Gamma=0.0015  ==> Prec:0.662  Recall:0.821  F1Score:0.733"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1500 Gamma=0.0020  ==> Prec:0.665  Recall:0.804  F1Score:0.728"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.1500 Gamma=0.0050  ==> Prec:0.677  Recall:0.730  F1Score:0.703"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.2500 Gamma=0.0005  ==> Prec:0.653  Recall:0.851  F1Score:0.739"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.2500 Gamma=0.0010  ==> Prec:0.660  Recall:0.832  F1Score:0.736"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.2500 Gamma=0.0015  ==> Prec:0.666  Recall:0.819  F1Score:0.735"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.2500 Gamma=0.0020  ==> Prec:0.670  Recall:0.806  F1Score:0.732"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.2500 Gamma=0.0050  ==> Prec:0.679  Recall:0.742  F1Score:0.709"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.5000 Gamma=0.0005  ==> Prec:0.657  Recall:0.849  F1Score:0.741"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.5000 Gamma=0.0010  ==> Prec:0.664  Recall:0.835  F1Score:0.740"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.5000 Gamma=0.0015  ==> Prec:0.667  Recall:0.826  F1Score:0.738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.5000 Gamma=0.0020  ==> Prec:0.671  Recall:0.815  F1Score:0.736"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.5000 Gamma=0.0050  ==> Prec:0.682  Recall:0.761  F1Score:0.720"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.8000 Gamma=0.0005  ==> Prec:0.658  Recall:0.846  F1Score:0.740"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.8000 Gamma=0.0010  ==> Prec:0.666  Recall:0.837  F1Score:0.742"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.8000 Gamma=0.0015  ==> Prec:0.669  Recall:0.831  F1Score:0.741"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.8000 Gamma=0.0020  ==> Prec:0.671  Recall:0.823  F1Score:0.739"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=0.8000 Gamma=0.0050  ==> Prec:0.681  Recall:0.770  F1Score:0.723"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Learning Curve"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Picking the best C and gamma (C=1, gamma=0.1)\n",
      "\n",
      "for n in [1000, 2000, 4000, 8000, 16000, 32000]:\n",
      "    Xsub, ysub = readRandomSample('/home/vahid/Downloads/data/ml/data_train.txt', y[0], size=n, goodfeat=goodfeatures)\n",
      "\n",
      "    ysub[np.where(ysub <= 156)[0]] = -1\n",
      "    ysub[np.where(ysub  > 156)[0]] =  1\n",
      "\n",
      "    #Xsub = Xsub[:, goodfeatures]\n",
      "    #Xsub = (Xsub - np.mean(Xsub, axis=0)) / np.std(Xsub, axis=0)\n",
      "    \n",
      "    sys.stderr.write('\\nSize = %d  ==> '%(n))\n",
      "    Tp = [0,0,0,0,0]\n",
      "    Fp = [0,0,0,0,0]\n",
      "    Tn = [0,0,0,0,0]\n",
      "    Fn = [0,0,0,0,0]\n",
      "    for i in range(5):\n",
      "        tr_idx = np.random.choice(n, size=n/2, replace=False)\n",
      "        ts_idx = np.setdiff1d(np.arange(n), tr_idx, assume_unique=True)\n",
      "        yts = ysub[ts_idx]\n",
      "\n",
      "        clf = sklearn.svm.SVC(C=1.0, kernel='rbf', gamma=0.10)\n",
      "        clf.fit(Xsub[tr_idx, :], ysub[tr_idx])\n",
      "        ypred = clf.predict(Xsub[ts_idx, :])\n",
      "        tp = np.sum(ypred[np.where(yts ==  1)[0]] == 1)\n",
      "        fp = np.sum(ypred[np.where(yts == -1)[0]] == 1)\n",
      "        tn = np.sum(ypred[np.where(yts == -1)[0]] == -1)\n",
      "        Tp[i], Fp[i], Tn[i], Fn[i] = tp, fp, tn, yts.shape[0]-(tp+fp+tn)\n",
      "        sys.stderr.write (\"%d (%d %d %d %d)\"%(i, tp, fp, tn, yts.shape[0]-(tp+fp+tn)))\n",
      "        \n",
      "    Tp_mean, Fp_mean, Tn_mean, Fn_mean = np.mean(Tp), np.mean(Fp), np.mean(Tn), np.mean(Fn)\n",
      "    recall  = Tp_mean / (Tp_mean + Fn_mean)\n",
      "    prec = Tp_mean / (Tp_mean + Fp_mean)\n",
      "    f1score = 2*Tp_mean/(2*Tp_mean + Fp_mean + Fn_mean)\n",
      "    sys.stderr.write('\\nAverage: Prec=%.3f  Recall=%.3f   F1-score=%.3f\\n'%(prec, recall, f1score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Size = 1000  ==> 0 (269 231 0 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "1 (251 249 0 0)2 (265 235 0 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "3 (271 229 0 0)4 (263 237 0 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Average: Prec=0.528  Recall=1.000   F1-score=0.691\n",
        "\n",
        "Size = 2000  ==> "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "0 (549 451 0 0)1 (549 451 0 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2 (542 458 0 0)3 (539 461 0 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "4 (550 450 0 0)\n",
        "Average: Prec=0.546  Recall=1.000   F1-score=0.706\n",
        "\n",
        "Size = 4000  ==> "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "0 (234 71 886 809)1 (255 89 896 760)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2 (276 77 910 737)3 (210 60 893 837)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "4 (295 97 898 710)\n",
        "Average: Prec=0.763  Recall=0.248   F1-score=0.374\n",
        "\n",
        "Size = 8000  ==> "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "0 (514 103 1773 1610)1 (527 106 1807 1560)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "2 (706 165 1779 1350)3 (573 133 1787 1507)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "4 (531 131 1799 1539)\n",
        "Average: Prec=0.817  Recall=0.274   F1-score=0.410\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-151-0a71d38fddc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mXsub\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mysub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadRandomSample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/home/vahid/Downloads/data/ml/data_train.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoodfeat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgoodfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mysub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mysub\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m156\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-149-1a123f2c8060>\u001b[0m in \u001b[0;36mreadRandomSample\u001b[1;34m(data_fname, y, size, goodfeat, acc_miny, acc_maxy)\u001b[0m\n\u001b[0;32m     35\u001b[0m                     \u001b[0mix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgoodfeat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m                             \u001b[0mix\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                             \u001b[0mXsub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Apply Logistic Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.linear_model\n",
      "\n",
      "# we create an instance of Neighbours Classifier and fit the data.\n",
      "n=20000\n",
      "Xsub, ysub = readRandomSample('/home/vahid/Downloads/data/ml/data_train.txt', y[0], size=n, goodfeat=goodfeatures)\n",
      "\n",
      "ysub[np.where(ysub <= 156)[0]] = -1\n",
      "ysub[np.where(ysub  > 156)[0]] =  1\n",
      "Xsub = (Xsub - np.mean(Xsub, axis=0)) / np.std(Xsub, axis=0)\n",
      "\n",
      "tr_idx = np.random.choice(n, size=n/2, replace=False)\n",
      "ts_idx = np.setdiff1d(np.arange(n), tr_idx, assume_unique=True)\n",
      "yts = ysub[ts_idx]\n",
      "\n",
      "for c in [1.0, 10.0, 100.0, 1000.0, 10000.0]:\n",
      "    logreg = sklearn.linear_model.LogisticRegression(C=c)\n",
      "    logreg.fit(Xsub[tr_idx,:], ysub[tr_idx])\n",
      "    ypred = logreg.predict(Xsub[ts_idx])\n",
      "    prec, recall, f1score = evalPerformance(yts, ypred)\n",
      "    print (\"C=%.4f ==> Prec:%.3f  Recall:%.3f  F1Score:%.3f\"%(c, prec, recall, f1score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "4146 1809 2912 1133\n",
        "4146 1808 2913 1133\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C=1.0000 Gamma=1.0000  ==> Prec:0.696  Recall:0.785  F1Score:0.738\n",
        "C=10.0000 Gamma=1.0000  ==> Prec:0.696  Recall:0.785  F1Score:0.738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=100.0000 Gamma=1.0000  ==> Prec:0.696  Recall:0.785  F1Score:0.738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "4145 1808 2913 1134\n",
        "4145 1808 2913 1134\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=1000.0000 Gamma=1.0000  ==> Prec:0.696  Recall:0.785  F1Score:0.738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C=10000.0000 Gamma=1.0000  ==> Prec:0.696  Recall:0.785  F1Score:0.738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "4145 1808 2913 1134\n"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Classify subclasses 156:164 \n",
      "\n",
      "**positive (+1): y==163:164**\n",
      "\n",
      "**negative (-1):  156 <= y <= 162**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Find good features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rdiff2 = calStandMeanDiff(y, np.arange(157,162), np.arange(162, 165))\n",
      "\n",
      "print(np.sum(rdiff2 > 0.1))\n",
      "goodfeatures_cs2 = np.where(rdiff2 > 0.1)[0]\n",
      "\n",
      "goodfeatures_cs2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "335\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Number of samples in NegClass: 235201 and PosClass: 287574 \n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 110,
       "text": [
        "array([  1,   2,   5,   6,   7,   8,  13,  15,  16,  17,  18,  20,  24,\n",
        "        25,  28,  31,  34,  35,  37,  38,  40,  43,  48,  50,  51,  52,\n",
        "        56,  57,  59,  61,  65,  69,  70,  71,  72,  79,  81,  84,  87,\n",
        "        90,  91,  92,  94,  97,  99, 101, 106, 110, 112, 118, 122, 127,\n",
        "       129, 133, 138, 139, 141, 143, 146, 148, 149, 151, 152, 153, 155,\n",
        "       158, 161, 163, 166, 167, 169, 175, 178, 179, 183, 184, 187, 188,\n",
        "       189, 196, 206, 208, 210, 217, 219, 221, 222, 224, 226, 229, 230,\n",
        "       237, 239, 246, 250, 253, 255, 256, 258, 261, 263, 267, 271, 272,\n",
        "       274, 277, 281, 287, 288, 289, 293, 294, 295, 305, 307, 308, 311,\n",
        "       313, 315, 316, 318, 320, 324, 328, 329, 330, 332, 334, 337, 338,\n",
        "       342, 343, 344, 348, 350, 353, 355, 357, 358, 359, 364, 366, 367,\n",
        "       372, 374, 381, 386, 388, 397, 400, 401, 402, 403, 404, 406, 407,\n",
        "       408, 409, 412, 413, 414, 416, 418, 419, 422, 428, 430, 432, 437,\n",
        "       440, 443, 445, 451, 457, 462, 464, 466, 467, 468, 470, 471, 473,\n",
        "       476, 484, 485, 486, 490, 492, 496, 498, 499, 500, 501, 504, 507,\n",
        "       510, 511, 516, 517, 524, 526, 528, 529, 530, 537, 539, 540, 541,\n",
        "       547, 548, 553, 556, 561, 564, 565, 566, 572, 576, 578, 579, 581,\n",
        "       582, 583, 585, 588, 590, 594, 600, 601, 602, 603, 605, 607, 608,\n",
        "       609, 610, 613, 615, 617, 628, 632, 633, 634, 641, 643, 645, 648,\n",
        "       651, 652, 653, 655, 656, 658, 661, 665, 666, 667, 669, 671, 673,\n",
        "       680, 681, 686, 692, 700, 701, 703, 711, 712, 714, 715, 716, 718,\n",
        "       719, 722, 723, 724, 726, 727, 728, 732, 735, 748, 751, 753, 757,\n",
        "       758, 759, 760, 762, 764, 770, 772, 773, 774, 775, 776, 778, 784,\n",
        "       785, 786, 790, 793, 794, 796, 798, 802, 806, 811, 815, 816, 817,\n",
        "       822, 823, 829, 833, 840, 848, 849, 852, 853, 854, 855, 858, 863,\n",
        "       864, 869, 871, 876, 884, 886, 890, 893, 894, 897])"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xsub, ysub = readRandomSample('/home/vahid/Downloads/data/ml/data_train.txt', y[0], size=20000, acc_miny=156, acc_maxy=164)\n",
      "\n",
      "ysub[np.where(ysub <= 162)[0]] = -1\n",
      "ysub[np.where(ysub  > 162)[0]] =  1\n",
      "\n",
      "Xsub = Xsub[:, goodfeatures]\n",
      "Xsub = (Xsub - np.mean(Xsub)) / np.std(Xsub)\n",
      "\n",
      "Xsub.shape\n",
      "\n",
      "ntot = Xsub.shape[0]\n",
      "tr_idx = np.random.choice(ntot, size=ntot/2, replace=False)\n",
      "ts_idx = np.setdiff1d(np.arange(ntot), tr_idx, assume_unique=True)\n",
      "yts = ysub[ts_idx]\n",
      "\n",
      "for c in [0.0001, 0.001, 0.01, 0.1, 1.0]:\n",
      "    for gm in [0.001, 0.01, 0.1, 1.0]:\n",
      "        clf = sklearn.svm.SVC(C=c, kernel='rbf', gamma=gm)\n",
      "        clf.fit(Xsub[tr_idx, :], ysub[tr_idx])\n",
      "        ypred = clf.predict(Xsub[ts_idx, :])\n",
      "        tp = np.sum(ypred[np.where(yts ==  1)[0]] == 1)\n",
      "        fp = np.sum(ypred[np.where(yts == -1)[0]] == 1)\n",
      "        tn = np.sum(ypred[np.where(yts == -1)[0]] == -1)\n",
      "        print (\"C=%.4f Gamma=%.4f  ==> TP:%d  FP:%d  TN:%d FN:%d\"%(c, gm, tp, fp, tn, yts.shape[0]-(tp+fp+tn)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "array([[-0.25956771,  1.89171015, -0.25956771,  0.81607122],\n",
        "       [-0.25956771, -0.25956771, -0.25956771,  0.0989786 ],\n",
        "       [-0.25956771,  0.0989786 , -0.25956771, -0.25956771]])"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = ['1', '2', '3']\n",
      "\n",
      "np.array(a).astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 135,
       "text": [
        "array([1, 2, 3])"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xtest = pandas.read_table('/home/vahid/Downloads/data/ml/data_test.txt', sep=\" \", usecols=goodfeatures, dtype='int', header=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xtest.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 138,
       "text": [
        "(262102, 332)"
       ]
      }
     ],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xtest[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>14</th>\n",
        "      <th>15</th>\n",
        "      <th>24</th>\n",
        "      <th>25</th>\n",
        "      <th>35</th>\n",
        "      <th>38</th>\n",
        "      <th>...</th>\n",
        "      <th>876</th>\n",
        "      <th>877</th>\n",
        "      <th>878</th>\n",
        "      <th>879</th>\n",
        "      <th>881</th>\n",
        "      <th>884</th>\n",
        "      <th>886</th>\n",
        "      <th>890</th>\n",
        "      <th>892</th>\n",
        "      <th>894</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>...</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>6</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>0</td>\n",
        "      <td>9</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 332 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 139,
       "text": [
        "   1    2    5    6    14   15   24   25   35   38  ...   876  877  878  879  \\\n",
        "0    0    0    0    0    0    0    3    2    0    0 ...     0    0    3    0   \n",
        "1    1    0    0    0    0    1    0    0    0    0 ...     0    0    0    0   \n",
        "2    5    0    4    0    4    0    0    0    0    1 ...     0    0    3    6   \n",
        "3    0    3    0    0    0    0    0    0    0    0 ...     2    0    3    0   \n",
        "4    0    9    0    0    0    1    3    0    0    0 ...     2    0    3    0   \n",
        "\n",
        "   881  884  886  890  892  894  \n",
        "0    0    0    0    0    2    0  \n",
        "1    1    1    1    1    0    0  \n",
        "2    0    0    0    0    1    1  \n",
        "3    0    0    0    0    0    1  \n",
        "4    0    0    0    0    0    1  \n",
        "\n",
        "[5 rows x 332 columns]"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}